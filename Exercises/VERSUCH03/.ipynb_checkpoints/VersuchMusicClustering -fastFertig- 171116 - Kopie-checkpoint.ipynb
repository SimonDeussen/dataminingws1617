{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining Versuch Music Clustering\n",
    "* Autor: Prof. Dr. Johannes Maucher\n",
    "* Datum: 16.10.2015\n",
    "\n",
    "[Übersicht Ipython Notebooks im Data Mining Praktikum](Data Mining Praktikum.ipynb)\n",
    "\n",
    "# Einführung\n",
    "## Lernziele:\n",
    "In diesem Versuch sollen Kenntnisse in folgenden Themen vermittelt werden:\n",
    "\n",
    "* Zugriff auf Musikdateien\n",
    "* Transcodierung von mp3 zu wav \n",
    "* Extraktion von Merkmalen in Musikdateien (Feature Extraction)\n",
    "* Optimierung mit dem genetischen Algorithmus\n",
    "* Selektion der aussagekräftigsten Merkmale (Feature Selection)\n",
    "* Clustering von Musikfiles (automatische Playlistgenerierung)\n",
    "\n",
    "## Theorie zur Vorbereitung\n",
    "\n",
    "### Numpy\n",
    "\n",
    "[Numpy Intro IPython Notebook](http://nbviewer.ipython.org/github/jrjohansson/scientific-python-lectures/blob/master/Lecture-2-Numpy.ipynb)\n",
    "\n",
    "1. Wie wird ein eindimensionales, wie ein zweidimensionales Numpy Array angelegt?\n",
    "2. Wie bestimmt man die Größe (Anzahl Zeilen und Anzahl Spalten) eines zweidimensionalen Numpy Arrays?\n",
    "3. Wie werden die Mittelwerte der Spalten eines Numpy Arrays ermittelt, wie werden die Standardabweichungen der Spalten eines Numpy Arrays berechnet?\n",
    "4. Wie können die Daten aus einem .csv File direkt in ein Numpy-Array eingelesen werden?\n",
    "5. Wie kann ein Numpy Array effizient in einem File abgespeichert werden? Wie können diese Daten aus dem File wieder in ein Numpy Array gelesen werden?\n",
    "6. Wie kann auf das Element in Zeile 1, Spalte 2 eines Numpy Arrays zugegriffen werden?\n",
    "7. Wie kann auf die zweite Zeile eines Numpy-Arrays zugegriffen werden?\n",
    "8. Wie kann auf die Spalten 2 bis 4 eines Numpy-Arrays zugegriffen werden?\n",
    "8. Wie kann das Skalarprodukt zweier eindimensionaler Numpy-Arrays bestimmt werden? \n",
    "9. Wie kann ein zweidimensionales Numpy-Array mit einem anderen zweidimensionales Numpy-Array multipliziert werden (im Sinne einer Matrixmultiplikation)? \n",
    "10. Wie kann ein eindimensionales Numpy Array mit einem zweidimensionalen Numpy Array multipliziert werden?\n",
    "11. Wie können Zeilen oder Spalten eines Numpy Arrays hinsichtlich ihrer Werte ansteigend oder absteigend sortiert werden?\n",
    "\n",
    "### Scipy\n",
    "\n",
    "[SciPy Intro IPython Notebook](http://nbviewer.ipython.org/github/jrjohansson/scientific-python-lectures/blob/master/Lecture-3-Scipy.ipynb)\n",
    "\n",
    "Machen Sie sich mit den Funktionen des Moduls [Scipy.spatial.distance](http://docs.scipy.org/doc/scipy-0.14.0/reference/spatial.distance.html#module-scipy.spatial.distance) vertraut.\n",
    "\n",
    "1. Wie wird die paarweise euklidische Distanz zwischen den Zeilen eines Numpy Array berechnet?\n",
    "\n",
    "Machen Sie sich mit den Funktionen des Moduls [Scipy.cluster.hierarchy](http://docs.scipy.org/doc/scipy/reference/cluster.hierarchy.html) vertraut.\n",
    "\n",
    "1. Wie wird mit diesem Modul ein hierarchisches Clustering von Vektoren berechnet und visualisiert?\n",
    "2. Welche Bedeutung haben die Parameter _method_ und _metric_ der Funktion _linkage_?  \n",
    "\n",
    "### Matplotlib\n",
    "\n",
    "[Matplotlib Intro IPython Notebook](http://nbviewer.ipython.org/github/jrjohansson/scientific-python-lectures/blob/master/Lecture-4-Matplotlib.ipynb)\n",
    "\n",
    "1. Machen Sie sich anhand des oben verlinkten Matplotlib mit den grundlegenden Plotting Funktionen dieses Pakets vertraut.\n",
    "\n",
    "\n",
    "\n",
    "### Pandas\n",
    "[10 Minutes to Pandas](http://pandas.pydata.org/pandas-docs/stable/10min.html)\n",
    "\n",
    "1. Was ist der Vorteil eines Pandas Dataframe gegenüber einem Numpy Array?\n",
    "2. Wie legt man eine Pandas Dataframe an?\n",
    "3. Wie liest man eine .csv Datei in einen Pandas Dataframe?\n",
    "4. Wie schreibt man einen Pandas Dataframe in eine .csv Datei?\n",
    "4. Wie greift man auf den Index eines Pandas Dataframes zu?\n",
    "4. Wie greift man auf die Spaltennamen eines Dataframes zu?\n",
    "5. Wie greift man auf eine Spalte eines Dataframes zu?\n",
    "6. Wie greift man auf eine Zeile eines Dataframes zu?\n",
    "\n",
    "\n",
    "\n",
    "## Vor dem Versuch zu klärende Fragen\n",
    "\n",
    "### Transcodierung von MP3 nach WAV und Merkmalsextraktion\n",
    "In diesem Versuch wird der MP3 Decoder [mpg123](http://www.mpg123.de/) eingesetzt. Installieren und testen sie diesen Decoder vor dem Versuch auf ihrem Rechner. Machen Sie sich zunächst mit dem in Kapitel [Gegebene Module zur Transcodierung und Feature Extraction](#Gegebene-Module-zur-Transcodierung-und-Feature-Extraction) aufgeführten Code vertraut. Versuchen Sie Funktion und Ablauf dieses Programms zu verstehen und beantworten Sie folgende Fragen.\n",
    "\n",
    "1. Was versteht man unter den statistischen Größen _Mittelwert, Standardabweichung, Skewness und Kurtosis_?\n",
    "2. Was beschreibt die Fourier-Transformierte eines zeitlich ausgedehnten Signals?\n",
    "3. Mit welcher Samplingrate werden die WAV Dateien abgetastet?\n",
    "4. Insgesamt werden 42 Merkmale pro Musiksequenz extrahiert. Beschreiben Sie kurz diese Merkmale\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##  Mittelwert\n",
    "\n",
    "Aus einer Anzahl von Zahlen wir nach einer bestimmten Rechenvorschrift eine weitere Zahl gebildet, die eine Art der Durchschnitts darstellt. Wiki: \"Der Mittelwert ist ein Kennwert für die zentrale Tendenz einer Verteilung\"\n",
    "\n",
    "## Standartabweichung\n",
    "\n",
    "Die Standartabweichung stellt die Streuung einer Wahrscheinlichkeitsverteilung um den Erwartungswert dar.Sie ist die Quadratwurzel der Varianz.\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/8/8c/Standard_deviation_diagram.svg/310px-Standard_deviation_diagram.svg.png\">\n",
    "\n",
    "## Skewness\n",
    "\n",
    "Beschreibt die Schiefe der Kurve der Verteilung. \n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dc/Linksschief.svg/203px-Linksschief.svg.png\">\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/c/cf/Rechtsschief.svg/188px-Rechtsschief.svg.png\">\n",
    "\n",
    "\n",
    "## Kurtosis\n",
    "Beschreibt die Wölbung der Kurve der Verteilung.\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/5/56/Steilgipflig.svg/197px-Steilgipflig.svg.png\">\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/f/f7/Flachgipflig.svg/212px-Flachgipflig.svg.png\">\n",
    "\n",
    "<hr>\n",
    "\n",
    "## Fourier-Transformation\n",
    "\n",
    "Die Fourier Transformation ist hier die Zerlegung eines Signals in dessen einzelne Frequenz Komponenten.\n",
    "<a href=\"https://www.youtube.com/watch?v=LznjC4Lo7lE\">Visualisierung hier</a>\n",
    "<hr>\n",
    "\n",
    "## Sampling\n",
    "\n",
    "Sie beträgt 10 kHz.\n",
    "\n",
    "## Features\n",
    "\n",
    "Es werden die Dynamik in verschieden Frequenzbereichen gemessen. N gibt den Bereich an. Es werden die wichtigen Statistischen Kennzahlen ermittelt. N = (1, 10, 100, 1000)\n",
    "\n",
    "+ ampNmean\n",
    "+ ampNstd\n",
    "+ ampNskew\n",
    "+ ampNkurt\n",
    " \n",
    "Das gleiche wird anschließend mit der Ableitung des Signals gemacht.\n",
    "\n",
    "+ ampNdmean\n",
    "+ ampNdstd\n",
    "+ ampNdskew\n",
    "+ ampNdkurt\n",
    "\n",
    "Schlussendlich wird die Durchschnittslautstärke, in 10 gleich großen Frequenzbereichen ermittelt N = (1,2,..10).\n",
    "\n",
    "+ powerN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matching der Teilsequenzen\n",
    "\n",
    "1. Nachdem für jedes Musikstück die beiden Teilsequenzen in Form der extrahierten Merkmale vorliegen: Wie kann die Ähnlichkeit zwischen Teilsequenzen ermittelt werden?\n",
    "2. Welche Numpy- bzw. Scipy-Module können Sie für die Bestimmung der Ähnlichkeit zwischen Teilsequenzen einsetzen?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "1. Durch eine Abstandsfunktion, zB Euklidische Distanz.\n",
    "<hr>\n",
    "2. scipy.spatial.distance liefert sehr viele Verschiedene Funktionen, wir werden zuerst mit Euklid arbeiten.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genetischer Algorithmus für die Merkmalsselektion\n",
    "\n",
    "1. Beschreiben Sie die Prozesschritte im genetischen Algorithmus [Genetischer Algorithmus](https://www.hdm-stuttgart.de/~maucher/Python/FunktionenAlgorithmen/html/genAlgTSP.html)\n",
    "2. In diesem Versuch wird davon ausgegangen, dass Merkmale dann gut sind, wenn durch sie die erste Teilsequenz eines Musikstücks durch einen ähnlichen Vektor wie die jeweils zweite Teilsequenz beschrieben wird. Wie kann mit dieser Annahme der genetische Algorithmus für die Merkmalsselektion angewandt werden. Unter Merkmalsselektion versteht man allgemein die Suche nach den $r$ besten Merkmalen aus einer Menge von insgesamt $R$ Merkmalen. In diesem Versuch werden initial $R=42$ Merkmale extrahiert, aus denen dann die besten $r<R$ Merkmale zu bestimmen sind. Überlegen Sie hierfür speziell wie die Fitnessfunktion, die Kreuzung und die Mutation zu realisieren sind.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Prozessschritte des Genetischen Algorithmus\n",
    "\n",
    "\n",
    "### Funktionsweiße Genetischer Algorithmus\n",
    "\n",
    "Aus einer Menge von Individuen die durch Chromosomen dargestellt werden, wird durch anwenden von verschiedenen Operationen die für die Problemstellung beste Lösung erzeugt. An Anfang ist die Belegung der Chomosomen zufällig. Diese wird dadurch verändert, dass die Individuen gekreuzt, selektiert, und mutiert werden. Bei einer Kruezung werden zufällig Merkmale ausgetauscht.\n",
    "Da es eine feste Menge an Individuen geben soll, muss nach einer Kreuzung ein Teil der Population wieder gelöscht werden. Hier werden die schlechten Ergebnisse aussortiert. Bei einer Mutation werden Chromosonen zufällig verändert. Die Operationen werden in einer Loop ausgeführt bis eine Abbruchbedingung erfüllt wird. Dies kann entweder ein feste Anzahl an Iterationen oder ein Schwellwert unter den ein Fehler fallen muss.\n",
    "Nach beendigung wird das Chromosom des besten Induviduums verwendet.\n",
    "\n",
    "\n",
    "<img src=\"https://www.hdm-stuttgart.de/~maucher/Python/FunktionenAlgorithmen/html/_images/AblaufGenAlg.jpg\">\n",
    "\n",
    "### Unsere Strategie\n",
    "\n",
    "1. Zufällige Population. Als Chromosomen werden wir einen binären Array mit 42 Einträgen benutzen. Die Einträge sagen aus welche Features in der Ähnlichkeitsmessung benutzt werden. Am Anfang sind alle zufällig belegt.\n",
    "\n",
    "2. Schleife bis Anzahl an Interationen erreicht:\n",
    "    + Berechne Fitness: Zugrunde liegt die Distanz zwischen 2 Songteilen, in unserer Version (Flag = 1) wird nur die euklidische Distanz benutzt, bei Hr. Mauchers Version, wird der Mittlere Rang der 2. Songhälfte benutzt. Je niedriger, desto besser\n",
    "    + Selektion: die N besten.\n",
    "    + Kreuzung: Ab einem Zufälligen Index werden die Chromosomen ausgetauscht.\n",
    "    + Mutation: X % der Individuum wird ein Feature umgedreht.\n",
    "  \n",
    "\n",
    "### Bei der Mutation\n",
    "\n",
    "Zwei Herangehensweisen: die zufällige Mutation eines Individuums und die zufällige Mutation eines Features jedes Individuums. Der Grund dafür war, dass wir herausfinden wollten, ob eine mit der zweiten Herangehensweise hereingehende deutlich höhere Mutationsrate zu einer Verbesserung (da wir in den ersten Tests Probleme mit dem Einpendeln auf lokalen Minima hatten) führt oder nur zu einer längeren Dauer, bis sich der GA auf einen gemeinsamen Wert einpendelt. Zum Testen verwandten wir gleiche Werte bei der Mutationsrate für die einzelnen Features und Individuen.\n",
    "In den Tests erwies sich die höhere Mutationsrate als positiv, da wir seltener auf lokalen Minima stießen. Die eventuell zusätzlich benötigte Zeit könnte sich bei einem umfangreicheren GA als kritisch erweisen, bei einem vergleichsweise kleinen wie dem unseren war der Unterschied jedoch nicht messbar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering und Playlistgenerierung\n",
    "\n",
    "1. Wie kann mit einem hierarchischen Clustering der Musikfiles eine Menge von Playlists erzeugt werden, so dass innerhalb einer Playlist möglichst ähnliche Titel zu finden sind?\n",
    "\n",
    "Bei einem hierarchichen Clustering wird eine Hierarchie aus Clustern aufgebaut. Ein Cluster wird jeweils aus zwei anderen Clustern aufgebaut. Beim ```linkage``` Clustering, wird beispielsweise ein N x 4 dimensionaler Vektor Z zurückgegeben, wobei N die Anzahl der Cluster ist. Für jeden Cluster wird die Distanz zwischen den zwei Clustern zurückgegeben aus denen er aufgebaut wurde. Will man nun eine Playlist generieren, könnte man z.B. eine bestimmte Distanz wählen. Für die Playlisten können dann die gefundenen Cluster verwendet die sich im Bereich der gewählten Distanz befinden. Je höher die Distanz, umso mehr Songs befinden sich in der Playlist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Durchführung\n",
    "## Gegebene Module zur Transcodierung und Feature Extraction\n",
    "Mit dem in diesem Abschnitt gegebenen Code werden die im Unterverzeichnis _BandCollection_ befindlichen mp3-Files zunächst in wave decodiert. Danach werden aus den wave Dateien Audiomerkmale erhoben.\n",
    "\n",
    "Von jedem Musikstück werden zwei disjunkte Teilsequenzen erhoben und von beiden Teilsequenzen jeweils ein Merkmalsvektor gebildet. Der Grund hierfür ist: Für die später folgende Bestimmung der wichtigsten Merkmale (Merkmalsselektion mit dem genetischen Algorithmus), wird angenommen dass Merkmale dann gut sind, wenn die aus ihnen gebildeten Merkmalsvektoren für Teilsequenzen des gleichen Musikstücks nahe beieinander liegen und die Merkmalsvektoren von Teilsequenzen unterschiedlicher Musikstücke weiter voneinander entfernt sind. In der Merkmalsselektion werden dann die Merkmale als relevant erachtet, für die diese Annahme zutrifft. \n",
    "\n",
    "**Aufgaben:**\n",
    "\n",
    "1. Stellen Sie im unten gegebenen Code die Verzeichnisse für Ihre Musikdateien (aktuell Unterverzeichnis _BandCollection_) und für den Ort Ihres _mpg123_ Decoders richtig ein.\n",
    "2. Die verwendete Musiksammlung sollte mindestens 5 verschiedene Interpreten möglichst unterschiedlicher Genres enthalten. Von jedem Interpret sollten mehrere Titel (evtl. ein ganzes Album) enthalten sein.\n",
    "3. Führen Sie den in diesem Abschnitt gegebenen Programmcode zur Audiofeature-Extraction aus. Damit werden für alle Musiksequenzen jeweils 42 Merkmale extrahiert. Die extrahierten Merkmalsvektoren der jeweils ersten Sequenz werden in das File _FeatureFileTrainingAllList1.csv_ geschrieben, die der zweiten Teilsequen in das File _FeatureFileTestAllList2.csv_. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import wave\n",
    "import struct\n",
    "import numpy\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "numpy.set_printoptions(precision=2,suppress=True)\n",
    "\n",
    "#Names of features extracted in this module\n",
    "FeatNames=[\"amp1mean\",\"amp1std\",\"amp1skew\",\"amp1kurt\",\"amp1dmean\",\"amp1dstd\",\"amp1dskew\",\"amp1dkurt\",\"amp10mean\",\"amp10std\",\n",
    "           \"amp10skew\",\"amp10kurt\",\"amp10dmean\",\"amp10dstd\",\"amp10dskew\",\"amp10dkurt\",\"amp100mean\",\"amp100std\",\"amp100skew\",\n",
    "           \"amp100kurt\",\"amp100dmean\",\"amp100dstd\",\"amp100dskew\",\"amp100dkurt\",\"amp1000mean\",\"amp1000std\",\"amp1000skew\",\n",
    "           \"amp1000kurt\",\"amp1000dmean\",\"amp1000dstd\",\"amp1000dskew\",\"amp1000dkurt\",\"power1\",\"power2\",\"power3\",\"power4\",\n",
    "           \"power5\",\"power6\",\"power7\",\"power8\",\"power9\",\"power10\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def moments(x):\n",
    "    mean = x.mean()\n",
    "    std = x.var()**0.5\n",
    "    skewness = ((x - mean)**3).mean() / std**3\n",
    "    kurtosis = ((x - mean)**4).mean() / std**4\n",
    "    return [mean, std, skewness, kurtosis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Feature category 2: Frequency domain parameters\n",
    "def fftfeatures(wavdata):\n",
    "    f = numpy.fft.fft(wavdata)\n",
    "    f = f[2:(f.size / 2 + 1)]\n",
    "    f = abs(f)\n",
    "    total_power = f.sum()\n",
    "    f = numpy.array_split(f, 10)\n",
    "    return [e.sum() / total_power for e in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Creating the entire feature vector per music-file\n",
    "def features(x):\n",
    "    x = numpy.array(x)\n",
    "    f = []\n",
    "\n",
    "    xs = x\n",
    "    diff = xs[1:] - xs[:-1]\n",
    "    f.extend(moments(xs))\n",
    "    f.extend(moments(diff))\n",
    "\n",
    "    xs = x.reshape(-1, 10).mean(1)\n",
    "    diff = xs[1:] - xs[:-1]\n",
    "    f.extend(moments(xs))\n",
    "    f.extend(moments(diff))\n",
    "\n",
    "    xs = x.reshape(-1, 100).mean(1)\n",
    "    diff = xs[1:] - xs[:-1]\n",
    "    f.extend(moments(xs))\n",
    "    f.extend(moments(diff))\n",
    "\n",
    "    xs = x.reshape(-1, 1000).mean(1)\n",
    "    diff = xs[1:] - xs[:-1]\n",
    "    f.extend(moments(xs))\n",
    "    f.extend(moments(diff))\n",
    "\n",
    "    f.extend(fftfeatures(x))\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def read_wav(wav_file):\n",
    "    \"\"\"Returns two chunks of sound data from wave file.\"\"\"\n",
    "    w = wave.open(wav_file)\n",
    "    n = 60 * 10000\n",
    "    if w.getnframes() < n * 3:\n",
    "        raise ValueError('Wave file too short')\n",
    "    #For each music file 2 sequences, each containing n frames are subtracted. The first sequence starts at postion n,\n",
    "    #the second sequence starts at postion 2n. The reason for extracting 2 subsequences is, that later on we like to\n",
    "    #find the best features and in this exercise we assume that good features have the property that they are similar for 2 subsequences\n",
    "    #of the same song, but differ for subsequences of different songs.\n",
    "    w.setpos(n)\n",
    "    frames = w.readframes(n)\n",
    "    wav_data1 = struct.unpack('%dh' % n, frames)\n",
    "    frames = w.readframes(n)\n",
    "    wav_data2 = struct.unpack('%dh' % n, frames)\n",
    "    return wav_data1, wav_data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def compute_chunk_features(mp3_file):\n",
    "    \"\"\"Return feature vectors for two chunks of an MP3 file.\"\"\"\n",
    "    # Extract MP3 file to a mono, 10kHz WAV file\n",
    "    #mpg123_command = 'C:\\Program Files (x86)\\mpg123-1.22.0-x86\\mpg123-1.22.0-x86\\\\mpg123.exe -w \"%s\" -r 10000 -m \"%s\"'\n",
    "    #mpg123_command = 'C:\\\\Program Files (x86)\\\\mpg123-1.21.0-x86-64\\\\mpg123.exe -w \"%s\" -r 10000 -m \"%s\"'\n",
    "    mpg123_command = 'D:\\\\Data Mining\\\\data\\\\mpg123-1.23.8-x86-64\\\\mpg123.exe -w \"%s\" -r 10000 -m \"%s\"'\n",
    "    out_file = 'temp.wav'\n",
    "    cmd = mpg123_command % (out_file, mp3_file)\n",
    "    temp = subprocess.call(cmd)\n",
    "    # Read in chunks of data from WAV file\n",
    "    wav_data1, wav_data2 = read_wav(out_file)\n",
    "    # We'll cover how the features are computed in the next section!\n",
    "    return numpy.array(features(wav_data1)), numpy.array(features(wav_data2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Data Mining\\data\\BandCollection\\Adele\\01 Hometown Glory.mp3\n",
      "--------------------Adele\\01 Hometown Glory.mp3--------------------\n",
      "D:\\Data Mining\\data\\BandCollection\\Adele\\02 I'll Be Waiting.mp3\n",
      "--------------------Adele\\02 I'll Be Waiting.mp3--------------------\n",
      "D:\\Data Mining\\data\\BandCollection\\Adele\\03 Don't You Remember.mp3\n",
      "--------------------Adele\\03 Don't You Remember.mp3--------------------\n",
      "D:\\Data Mining\\data\\BandCollection\\Adele\\04 Turning Tables.mp3\n",
      "--------------------Adele\\04 Turning Tables.mp3--------------------\n",
      "D:\\Data Mining\\data\\BandCollection\\Adele\\05 Set Fire To The Rain.mp3\n",
      "--------------------Adele\\05 Set Fire To The Rain.mp3--------------------\n",
      "D:\\Data Mining\\data\\BandCollection\\Adele\\06 If It Hadn't Been For Love.mp3\n",
      "--------------------Adele\\06 If It Hadn't Been For Love.mp3--------------------\n",
      "D:\\Data Mining\\data\\BandCollection\\Adele\\07 My Same.mp3\n",
      "Error: Chunk Features failed\n",
      "D:\\Data Mining\\data\\BandCollection\\Adele\\08 Take It All.mp3\n",
      "--------------------Adele\\08 Take It All.mp3--------------------\n",
      "D:\\Data Mining\\data\\BandCollection\\Adele\\09 Rumour Has It.mp3\n",
      "--------------------Adele\\09 Rumour Has It.mp3--------------------\n",
      "D:\\Data Mining\\data\\BandCollection\\Adele\\10 Right As Rain.mp3\n",
      "Error: Chunk Features failed\n",
      "D:\\Data Mining\\data\\BandCollection\\Adele\\11 One And Only.mp3\n",
      "--------------------Adele\\11 One And Only.mp3--------------------\n",
      "D:\\Data Mining\\data\\BandCollection\\Adele\\12 Lovesong.mp3\n",
      "--------------------Adele\\12 Lovesong.mp3--------------------\n",
      "D:\\Data Mining\\data\\BandCollection\\Adele\\13 Chasing Pavements.mp3\n",
      "--------------------Adele\\13 Chasing Pavements.mp3--------------------\n",
      "D:\\Data Mining\\data\\BandCollection\\Adele\\14 I Can't Make You Love Me.mp3\n",
      "--------------------Adele\\14 I Can't Make You Love Me.mp3--------------------\n",
      "D:\\Data Mining\\data\\BandCollection\\Adele\\15 Make You Feel My Love.mp3\n",
      "--------------------Adele\\15 Make You Feel My Love.mp3--------------------\n",
      "D:\\Data Mining\\data\\BandCollection\\Adele\\16 Someone Like You.mp3\n",
      "--------------------Adele\\16 Someone Like You.mp3--------------------\n",
      "D:\\Data Mining\\data\\BandCollection\\Adele\\17 Rolling In The Deep.mp3\n",
      "--------------------Adele\\17 Rolling In The Deep.mp3--------------------\n",
      "D:\\Data Mining\\data\\BandCollection\\BeastieBoys\\01 So What'cha Want.mp3\n",
      "--------------------BeastieBoys\\01 So What'cha Want.mp3--------------------\n",
      "D:\\Data Mining\\data\\BandCollection\\BeastieBoys\\02 Brass Monkey.mp3\n",
      "Error: Chunk Features failed\n",
      "D:\\Data Mining\\data\\BandCollection\\BeastieBoys\\03 Ch-Check It Out.mp3\n",
      "--------------------BeastieBoys\\03 Ch-Check It Out.mp3--------------------\n",
      "D:\\Data Mining\\data\\BandCollection\\BeastieBoys\\04 No Sleep Till Brooklyn.mp3\n",
      "--------------------BeastieBoys\\04 No Sleep Till Brooklyn.mp3--------------------\n",
      "D:\\Data Mining\\data\\BandCollection\\BeastieBoys\\05 Hey Ladies.mp3\n",
      "--------------------BeastieBoys\\05 Hey Ladies.mp3--------------------\n",
      "D:\\Data Mining\\data\\BandCollection\\BeastieBoys\\06 Pass the Mic.mp3\n",
      "--------------------BeastieBoys\\06 Pass the Mic.mp3--------------------\n",
      "D:\\Data Mining\\data\\BandCollection\\BeastieBoys\\07 An Open Letter to NYC.mp3\n",
      "--------------------BeastieBoys\\07 An Open Letter to NYC.mp3--------------------\n",
      "D:\\Data Mining\\data\\BandCollection\\BeastieBoys\\08 Root Down.mp3\n",
      "--------------------BeastieBoys\\08 Root Down.mp3--------------------\n",
      "D:\\Data Mining\\data\\BandCollection\\BeastieBoys\\09 Shake Your Rump.mp3\n",
      "--------------------BeastieBoys\\09 Shake Your Rump.mp3--------------------\n",
      "D:\\Data Mining\\data\\BandCollection\\BeastieBoys\\10 Intergalactic.mp3\n",
      "--------------------BeastieBoys\\10 Intergalactic.mp3--------------------\n",
      "D:\\Data Mining\\data\\BandCollection\\BeastieBoys\\11 Sure Shot.mp3\n",
      "--------------------BeastieBoys\\11 Sure Shot.mp3--------------------\n",
      "D:\\Data Mining\\data\\BandCollection\\BeastieBoys\\12 Body Movin' (Fatboy Slim Remix).mp3\n",
      "--------------------BeastieBoys\\12 Body Movin' (Fatboy Slim Remix).mp3--------------------\n",
      "D:\\Data Mining\\data\\BandCollection\\BeastieBoys\\13 Triple Trouble.mp3\n",
      "Error: Chunk Features failed\n",
      "D:\\Data Mining\\data\\BandCollection\\BeastieBoys\\14 Sabotage.mp3\n",
      "Error: Chunk Features failed\n",
      "D:\\Data Mining\\data\\BandCollection\\BeastieBoys\\15 Fight for Your Right.mp3\n",
      "--------------------BeastieBoys\\15 Fight for Your Right.mp3--------------------\n",
      "D:\\Data Mining\\data\\BandCollection\\Garrett\\01 Smooth Criminal 1.mp3\n",
      "--------------------Garrett\\01 Smooth Criminal 1.mp3--------------------\n",
      "D:\\Data Mining\\data\\BandCollection\\Garrett\\02 Who Wants to Live Forever_ 1.mp3\n",
      "--------------------Garrett\\02 Who Wants to Live Forever_ 1.mp3--------------------\n",
      "D:\\Data Mining\\data\\BandCollection\\Garrett\\03 Clair de Lune 1.mp3\n",
      "--------------------Garrett\\03 Clair de Lune 1.mp3--------------------\n",
      "D:\\Data Mining\\data\\BandCollection\\Garrett\\04 He's a Pirate (Pirates of the Car 1.mp3\n",
      "--------------------Garrett\\04 He's a Pirate (Pirates of the Car 1.mp3--------------------\n",
      "D:\\Data Mining\\data\\BandCollection\\Garrett\\05 Summertime 1.mp3\n",
      "--------------------Garrett\\05 Summertime 1.mp3--------------------\n",
      "D:\\Data Mining\\data\\BandCollection\\Garrett\\06 Brahms Hungarian Dance No. 5 1.mp3\n",
      "Error: Chunk Features failed\n",
      "D:\\Data Mining\\data\\BandCollection\\Garrett\\07 Chelsea Girl 1.mp3\n",
      "Error: Chunk Features failed\n",
      "D:\\Data Mining\\data\\BandCollection\\Garrett\\08 Summer 1.mp3\n",
      "Error: Chunk Features failed\n",
      "D:\\Data Mining\\data\\BandCollection\\Garrett\\09 O Mio Babbino Caro 1.mp3\n",
      "--------------------Garrett\\09 O Mio Babbino Caro 1.mp3--------------------\n",
      "D:\\Data Mining\\data\\BandCollection\\Garrett\\10 Air.mp3\n",
      "--------------------Garrett\\10 Air.mp3--------------------\n",
      "D:\\Data Mining\\data\\BandCollection\\Garrett\\11 Thunderstruck.mp3\n",
      "--------------------Garrett\\11 Thunderstruck.mp3--------------------\n",
      "D:\\Data Mining\\data\\BandCollection\\Garrett\\12 New Day.mp3\n",
      "--------------------Garrett\\12 New Day.mp3--------------------\n",
      "D:\\Data Mining\\data\\BandCollection\\Garrett\\13 Ain't No Sunshine.mp3\n",
      "Error: Chunk Features failed\n",
      "D:\\Data Mining\\data\\BandCollection\\Garrett\\14 Rock Prelude.mp3\n",
      "--------------------Garrett\\14 Rock Prelude.mp3--------------------\n",
      "D:\\Data Mining\\data\\BandCollection\\Garrett\\15 Winter Lullaby.mp3\n",
      "Error: Chunk Features failed\n",
      "D:\\Data Mining\\data\\BandCollection\\Garrett\\16 Little Wing.mp3\n",
      "--------------------Garrett\\16 Little Wing.mp3--------------------\n",
      "D:\\Data Mining\\data\\BandCollection\\LanaDelRey\\01 Born to Die.mp3\n",
      "--------------------LanaDelRey\\01 Born to Die.mp3--------------------\n",
      "D:\\Data Mining\\data\\BandCollection\\LanaDelRey\\02 Off to the Races.mp3\n",
      "--------------------LanaDelRey\\02 Off to the Races.mp3--------------------\n",
      "D:\\Data Mining\\data\\BandCollection\\LanaDelRey\\03 Blue Jeans (Remastered).mp3\n",
      "--------------------LanaDelRey\\03 Blue Jeans (Remastered).mp3--------------------\n",
      "D:\\Data Mining\\data\\BandCollection\\LanaDelRey\\04 Video Games (Remastered).mp3\n",
      "--------------------LanaDelRey\\04 Video Games (Remastered).mp3--------------------\n",
      "D:\\Data Mining\\data\\BandCollection\\LanaDelRey\\05 Diet Mountain Dew.mp3\n",
      "--------------------LanaDelRey\\05 Diet Mountain Dew.mp3--------------------\n",
      "D:\\Data Mining\\data\\BandCollection\\LanaDelRey\\06 National Anthem.mp3\n",
      "--------------------LanaDelRey\\06 National Anthem.mp3--------------------\n",
      "D:\\Data Mining\\data\\BandCollection\\LanaDelRey\\07 Dark Paradise.mp3\n",
      "--------------------LanaDelRey\\07 Dark Paradise.mp3--------------------\n",
      "D:\\Data Mining\\data\\BandCollection\\LanaDelRey\\08 Radio.mp3\n",
      "--------------------LanaDelRey\\08 Radio.mp3--------------------\n",
      "D:\\Data Mining\\data\\BandCollection\\LanaDelRey\\09 Carmen.mp3\n",
      "--------------------LanaDelRey\\09 Carmen.mp3--------------------\n",
      "D:\\Data Mining\\data\\BandCollection\\LanaDelRey\\10 Million Dollar Man.mp3\n",
      "--------------------LanaDelRey\\10 Million Dollar Man.mp3--------------------\n",
      "D:\\Data Mining\\data\\BandCollection\\LanaDelRey\\11 Summertime Sadness.mp3\n",
      "--------------------LanaDelRey\\11 Summertime Sadness.mp3--------------------\n",
      "D:\\Data Mining\\data\\BandCollection\\LanaDelRey\\12 This Is What Makes Us Girls.mp3\n",
      "--------------------LanaDelRey\\12 This Is What Makes Us Girls.mp3--------------------\n",
      "D:\\Data Mining\\data\\BandCollection\\RageAgainstTheMachine\\01 Bombtrack.mp3\n",
      "--------------------RageAgainstTheMachine\\01 Bombtrack.mp3--------------------\n",
      "D:\\Data Mining\\data\\BandCollection\\RageAgainstTheMachine\\02 Killing In the Name.mp3\n",
      "--------------------RageAgainstTheMachine\\02 Killing In the Name.mp3--------------------\n",
      "D:\\Data Mining\\data\\BandCollection\\RageAgainstTheMachine\\03 Take the Power Back.mp3\n",
      "--------------------RageAgainstTheMachine\\03 Take the Power Back.mp3--------------------\n",
      "D:\\Data Mining\\data\\BandCollection\\RageAgainstTheMachine\\04 Settle for Nothing.mp3\n",
      "--------------------RageAgainstTheMachine\\04 Settle for Nothing.mp3--------------------\n",
      "D:\\Data Mining\\data\\BandCollection\\RageAgainstTheMachine\\05 Bullet In the Head.mp3\n",
      "--------------------RageAgainstTheMachine\\05 Bullet In the Head.mp3--------------------\n",
      "D:\\Data Mining\\data\\BandCollection\\RageAgainstTheMachine\\06 Know Your Enemy.mp3\n",
      "--------------------RageAgainstTheMachine\\06 Know Your Enemy.mp3--------------------\n",
      "D:\\Data Mining\\data\\BandCollection\\RageAgainstTheMachine\\07 Wake Up.mp3\n",
      "--------------------RageAgainstTheMachine\\07 Wake Up.mp3--------------------\n",
      "D:\\Data Mining\\data\\BandCollection\\RageAgainstTheMachine\\08 Fistful of Steel.mp3\n",
      "--------------------RageAgainstTheMachine\\08 Fistful of Steel.mp3--------------------\n",
      "D:\\Data Mining\\data\\BandCollection\\RageAgainstTheMachine\\09 Township Rebellion.mp3\n",
      "--------------------RageAgainstTheMachine\\09 Township Rebellion.mp3--------------------\n",
      "D:\\Data Mining\\data\\BandCollection\\RageAgainstTheMachine\\10 Freedom.mp3\n",
      "--------------------RageAgainstTheMachine\\10 Freedom.mp3--------------------\n"
     ]
    }
   ],
   "source": [
    "fileList=[]\n",
    "featureList1=[]\n",
    "featureList2=[]\n",
    "#Specify the name of the directory, which contains your MP3 files here.\n",
    "# This directory should contain for each band/author one subdirectory, which contains all songs of this author\n",
    "for path, dirs, files in os.walk('D:\\\\Data Mining\\\\data\\\\BandCollection'):\n",
    "    #print '-'*10,dirs,files\n",
    "    for f in files:\n",
    "        if not f.endswith('.mp3'):\n",
    "            # Skip any non-MP3 files\n",
    "            continue\n",
    "        mp3_file = os.path.join(path, f)\n",
    "        print mp3_file\n",
    "        # Extract the track name (i.e. the file name) plus the names\n",
    "        # of the two preceding directories. This will be useful\n",
    "        # later for plotting.\n",
    "        tail, track = os.path.split(mp3_file)\n",
    "        tail, dir1 = os.path.split(tail)\n",
    "        tail, dir2 = os.path.split(tail)\n",
    "        # Compute features. feature_vec1 and feature_vec2 are lists of floating\n",
    "        # point numbers representing the statistical features we have extracted\n",
    "        # from the raw sound data.\n",
    "        try:\n",
    "            feature_vec1, feature_vec2 = compute_chunk_features(mp3_file)\n",
    "        except:\n",
    "            print \"Error: Chunk Features failed\"\n",
    "            continue\n",
    "        #title=str(track)\n",
    "        title=str(dir1)+'\\\\'+str(track)\n",
    "        print '-'*20+ title +'-'*20\n",
    "        #print \"       feature vector 1:\",feature_vec1\n",
    "        #print \"       feature vector 2:\",feature_vec2\n",
    "        fileList.append(title)\n",
    "        featureList1.append(feature_vec1)\n",
    "        featureList2.append(feature_vec2)\n",
    "\n",
    "# Write feature vecotrs of all music files to pandas data-frame\n",
    "MusicFeaturesTrain=pd.DataFrame(index=fileList,data=numpy.array(featureList1),columns=FeatNames)\n",
    "MusicFeaturesTrain.to_csv(\"FeatureFileTrainingAllList1.csv\")\n",
    "\n",
    "MusicFeaturesTest=pd.DataFrame(index=fileList,data=numpy.array(featureList2),columns=FeatNames)\n",
    "MusicFeaturesTest.to_csv(\"FeatureFileTestAllList2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Matching der Teilsequenzen\n",
    "In diesem Abschnitt soll ein Verfahren implementiert werden, mit dem die Übereinstimmung der ersten Teilsequenz eines Musikstücks mit den zweiten Teilsequenzen aller anderen Musikstücke berechnet werden kann.\n",
    "\n",
    "**Aufagben:**\n",
    "1. Lesen Sie die im vorigen Teilversuch angelegten zwei csv-Dateien in jeweils einen eigenen Pandas Dataframe ein.\n",
    "2. Bestimmen Sie zu jeder Teilsequenz aus der Datei _FeatureFileTrainingAllList1.csv_ die euklidische Distanz zu allen Teilsequenzen aus der Datei _FeatureFileTestAllList2.csv_ und schreiben Sie diese Distanzen in eine aufsteigend geordnete Liste. Schreiben Sie auch die zugehörigen Argumente (Teilsequenzen) in eine geordnete Liste, sodass für jede Teilsequenz aus _FeatureFileTrainingAllList1.csv_ die am nächsten liegende Teilsequenz aus _FeatureFileTestAllList2.csv_ an erster Stelle steht, die zweitnächste Teilsequenz an zweiter usw.\n",
    "3. Bestimmen Sie über alle Teilsequenzen aus _FeatureFileTrainingAllList1.csv_ den **mittleren Rang** an dem die zugehörige zweite Teilsequenz erscheint. Liegt z.B. für die erste Teilsequenz des Musikstücks A die zweite Teilsequenz nur an fünfter Stelle der geordneten nächsten Nachbarliste. Dann würde diese Teilsequenz mit dem Rang 5 in den Mittelwert einfließen.\n",
    "4. Bestimmen Sie jetzt den mittleren Rang, für den Fall, dass _correlation_ anstelle _euclidean_ als Ähnlichkeitsmaß verwendet wird. Welches Ähnlichkeitsmaß ist für diese Anwendung zu bevorzugen?\n",
    "5. Diskutieren Sie das Ergebnis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean function: 4.35\n",
      "Correlation function: 2.96666666667\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import scipy\n",
    "import scipy.spatial\n",
    "#----------------------------------------Matching der Teilsequenzen Aufgabe 2 Quellcode-------------------------------------\n",
    "\n",
    "FeatureFileTestAllList2 = pd.read_csv(\"FeatureFileTestAllList2.csv\")\n",
    "FeatureFileTrainingAllList1 = pd.read_csv(\"FeatureFileTrainingAllList1.csv\")\n",
    "\n",
    "def sortByArray(X, Y):\n",
    "    return [x for (y,x) in sorted(zip(Y,X))]\n",
    "\n",
    "def getSongNames(trainData):\n",
    "    \"Returns an array of the song_names and a corresponding matrix of the feature data\"\n",
    "    trainMatrix = trainData.as_matrix()\n",
    "    songList = trainMatrix[:,0]\n",
    "    featureData = trainMatrix[:,1:]\n",
    "    return (songList, featureData)\n",
    "\n",
    "def calculate_mean_rank(trainDf, testDf, correlation):\n",
    "    \"Calculate the mean rank of the correlating songs with the use of the provided correlation function\"\n",
    "    \n",
    "    (trainSongs, trainData) = getSongNames(trainDf)\n",
    "    (testSongs, testData) = getSongNames(testDf)\n",
    "\n",
    "    # Create a songs x correlations matrix, where correlations is the correlation between each song\n",
    "    # and all other songs in the test data\n",
    "    correlations_matrix = [[correlation(trainArray, testArray) for testArray in testData] for trainArray in trainData]\n",
    "    \n",
    "    # Create a songs x arguments matrix, where songs is each song in the train data and arguments is each argument of\n",
    "    # the test data set \n",
    "    arguments_matrix = [[testArray for testArray in testData] for trainArray in trainData]\n",
    "\n",
    "    # Sort arguments_matrix and song names by the calculated correlations\n",
    "    (correlations_matrix, arguments_matrix, songname_matrix) = zip(*[zip(*sorted(zip(correlations, arguments, testSongs))) \n",
    "                                                                     for correlations, arguments \n",
    "                                                                     in zip(correlations_matrix, arguments_matrix)])\n",
    "\n",
    "    # Find the ranks of each song in the train data in the song name matrix \n",
    "    # (was previously sorted according to the correlations)\n",
    "    ranks = [songs.index(x) for songs, x in zip(songname_matrix, trainSongs)]\n",
    "    \n",
    "    # Calculate the mean value\n",
    "    return float(sum(ranks))/len(ranks)\n",
    "\n",
    "(trainSongs, trainData) = getSongNames(FeatureFileTrainingAllList1)\n",
    "(testSongs, testData) = getSongNames(FeatureFileTestAllList2)\n",
    "\n",
    "print \"Euclidean function:\",  calculate_mean_rank(FeatureFileTrainingAllList1, FeatureFileTestAllList2, scipy.spatial.distance.euclidean)\n",
    "print \"Correlation function:\",  calculate_mean_rank(FeatureFileTrainingAllList1, FeatureFileTestAllList2, scipy.spatial.distance.correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\simon\\AppData\\Local\\Enthought\\Canopy\\User\\lib\\site-packages\\sklearn\\utils\\validation.py:429: DataConversionWarning: Data with input dtype object was converted to float64 by the normalize function.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "import sklearn.preprocessing as pp\n",
    "\n",
    "# --------------------------- NORMALIZATION \n",
    "for i in range(42):\n",
    "    trainData[:,i] = pp.normalize(trainData[:,i].reshape(1, -1), norm='l2') \n",
    "    testData[:,i] = pp.normalize(testData[:,i].reshape(1, -1), norm='l2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 4 - Diskussion\n",
    "\n",
    "Der durchschnittliche Rang ist unter Verwendung der Euklidischen Distanz um ca. 1.4 höher. D.h. dass die Teilsequenzen der gleichen Lieder im Durchschnitt eine geringere Ähnlichkeit haben als unter der Verwendung der Correlation Distance. Das Ergebnis spricht also dafür die Correlation Distance in Zukunft zu verwenden, da Sequenzen der gleichen Lieder im Durchschnitt als ähnlicher eingestuft werden.\n",
    "\n",
    "Die Correlation Distance misst vor Allem die linearen Abhängigkeiten zwischen Vektoren und wird somit nicht von der Skalierung von Vektoren beeinflusst."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 5 - Diskussion\n",
    "\n",
    "Für einen großen Teil der Teilsequenzen ist die Ähnlichkeit innerhalb des Liedes schon relativ hoch. Allerdings gibt es auch einen nicht unerheblichen Teil der Lieder, bei denen die Distanz zwischen zwei Teilsequenzen des gleichen Liedes sehr hoch ist. Beispiel der einzelnen Ränge unter Anwendung der Correlation Distance:\n",
    "\n",
    "\n",
    "[0, 2, 7, 2, 1, 6, 1, 7, 7, 2, 0, 9, 0, 11, 1, 0, 0, 0, 0, 0, 4, 0, 0, 1, 0, 0, 1, 0, 9, 8, 1, 0, 1, 0, 2, 8, 15, 0, 0, 4, 8, 3, 0, 2, 0, 1, 2, 0, 0, 17, 7, 0, 2, 11, 8, 5, 1, 0, 0, 1]\n",
    "\n",
    "\n",
    "\n",
    "Diese \"Ausreißer\" beeinflussen zu einem hohen Maß den durchschnittlichen Rang. Das Problem tritt höchstwahrscheinlich auf, da die Vektoren zur Zeit noch auf Basis aller 42 Merkmale verglichen werden. Dies muss in den folgenden Aufgaben mithilfe eines (genetischen) Algorithmus gelöst werden, so dass für einen Song jeweils aussagekräftige Merkmale gefunden werden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merkmalsauswahl mit dem genetischen Algorithmus\n",
    "In diesem Abschnitt soll unter Anwendung eines selbst zu implementierenden genetischen Algorithmus eine Untermenge wichtiger Merkmale aus den insgesamt 42 angelegten Merkmalen berechnet werden.\n",
    "Als Vorlage kann hierfür die Implementierung für die [Lösung des TSP Problems](https://www.hdm-stuttgart.de/~maucher/Python/FunktionenAlgorithmen/html/genAlgTSP.html) herangezogen werden. Anzupassen sind dann jedoch mindestens die Fitness-Funktion, die Kreuzungs- und die Mutationsfunktion. Die Fitness soll so wie im vorigen Teilabschnitt mit dem mittleren Rang berechnet werden. Die Populationsgröße, die Anzahl der auszuwählenden Merkmale und die Anzahl der Iterationen sollen als Parameter einstellbar sein.\n",
    "\n",
    "Der Fitnesswert des besten Individuums in der Population soll in jeder Iteration gespeichert werden. Der Verlauf dieses besten Fitness-Wertes über den Fortlauf der Iterationen soll graphisch ausgegeben werden.\n",
    "\n",
    "Ein Pandas Frame, der nur die berechneten wichtigsten Merkmale aus _FeatureFileTrainingAllList1.csv_ enthält soll angelegt und in die csv Datei _subFeaturesTrain1.csv_ geschrieben werden.\n",
    "\n",
    "**Aufgaben:**\n",
    "1. Implementieren Sie die die Merkmalsauswahl mit dem genetischen Algorithmus entsprechend der o.g. Beschreibung\n",
    "2. Beschreiben Sie kurz das Konzept ihrer Kreuzungs- und Mutationsfunktion. \n",
    "3. Bestimmen Sie eine möglichst kleine Merkmalsuntermenge mit einem möglichst guten mittleren Rang? Geben Sie sowohl die gefundenen wichtigsten Merkmale als auch den zugehörigen mittleren Rang an.\n",
    "4. Um wieviel verschlechtert sich der Mittlere Rang, wenn nur die 10 wichtigsten Merkmale benutzt werden?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Genetischer Algorithmus für die Music Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from scipy.spatial.distance import correlation\n",
    "from scipy.spatial.distance import euclidean\n",
    "#from __future__ import division\n",
    "\n",
    "\n",
    "class Individuum():\n",
    "    def __init__(self, featureList, score=0):\n",
    "        self.featureList = featureList\n",
    "        self.score = score     \n",
    "    \n",
    "def createRandomChromosom():\n",
    "    return [bool(random.getrandbits(1)) for x in range(42)]\n",
    "\n",
    "def makeChild(parent1, parent2, weightParaCount, mutationRate, flag, flagMutation):\n",
    "    c = makeCrossover(parent1, parent2, mutationRate, flagMutation)\n",
    "    r = Individuum(c)\n",
    "    r.score = createScore(r, trainData, testData, weightParaCount, flag)\n",
    "    return r\n",
    "\n",
    "def makeCrossover(parent1, parent2, mutationRate, flagMutation):\n",
    "    newChromosom = parent1.featureList\n",
    "    parentList = parent2.featureList\n",
    "    __index1 = np.random.random_integers(42)\n",
    "\n",
    "    for x in range(__index1,42):\n",
    "        newChromosom[x] = parentList[x]\n",
    "\n",
    "    #DEFAULT: MUTATE AN INDIVIDUAL —> LOW CHANCE OF MUTATION\n",
    "    if (flagMutation == 1):\n",
    "        if np.random <= mutationRate:\n",
    "            j = np.random.random_integers(41)\n",
    "            newChromosom[j] = not newChromosom[j]\n",
    "    #ALTERNATE: MUTATE FEATURES OF EVERY INDIVIDUAL —> HIGH CHANCE OF MUTATION\n",
    "    elif (flagMutation == 2):\n",
    "        for i in range(len(newChromosom)):\n",
    "            if random.random <= mutationRate:\n",
    "                newChromosom[i] = not newChromosom[i]\n",
    "\n",
    "    #ERROR\n",
    "    else:\n",
    "        print \"Wrong flag. Choose 1=individual or 2=feature.\"\n",
    "\n",
    "\n",
    "    return newChromosom\n",
    "\n",
    "\n",
    "\n",
    "def getReducedAttributeListSize(individuum):\n",
    "    __index2 = 0\n",
    "    fL = individuum.featureList        \n",
    "    for x in range(42):\n",
    "        if fL[x]:\n",
    "            __index2 = __index2 + 1\n",
    "            \n",
    "    return __index2\n",
    "\n",
    "def createReducedAttributeList(individuum, trainArray, testArray):\n",
    "    size = getReducedAttributeListSize(individuum)\n",
    "    feat1 = [0 for i in range(size)]\n",
    "    feat2 = [0 for i in range(size)]\n",
    "       \n",
    "    __index3 = 0\n",
    "    fL = individuum.featureList\n",
    "    \n",
    "    for y in range(len(fL)):\n",
    "        if fL[y]:\n",
    "            feat1[__index3] = trainArray[y]\n",
    "            feat2[__index3] = testArray[y]\n",
    "            __index3 = __index3 + 1\n",
    "    \n",
    "    return feat1,feat2\n",
    "\n",
    "def rateFeatureList(individuum, trainArray, testArray, weightParaCount):\n",
    "    (__ft1,__ft2) = createReducedAttributeList(individuum, trainArray, testArray)\n",
    "    return euclidean(__ft1,__ft2)/(getReducedAttributeListSize(individuum)*weightParaCount)\n",
    "\n",
    "        \n",
    "def createScore(individuum, trainData, testData, weightParaCount, flag):\n",
    "    if flag==1:\n",
    "        scoresPerSong = [rateFeatureList(individuum, trainData[i], testData[i], weightParaCount) for i in range(60)]\n",
    "        return np.mean(scoresPerSong)\n",
    "    elif flag==2:\n",
    "        scoreSort =[]\n",
    "\n",
    "        for index1 in range(len(trainData)):\n",
    "            score = [i for i in range(60)]\n",
    "            scoreList = []\n",
    "\n",
    "            for index in range(len(testData)):\n",
    "                scoreList.append(rateFeatureList(individuum, trainData[index1], testData[index], weightParaCount))\n",
    "\n",
    "            (sortScore, sortScoreList) = sortByArray(score, scoreList)\n",
    "\n",
    "            for index2 in range(len(sortScore)):\n",
    "                if sortScore[index2] == index1:\n",
    "                    scoreSort.append(index2)\n",
    "\n",
    "\n",
    "        scoreSort.sort()\n",
    "        median = len(scoreSort)/2\n",
    "        return scoreSort[median]+1\n",
    "    elif flag==3:\n",
    "        scoreSort =[]\n",
    "\n",
    "        for index1 in range(len(trainData)):\n",
    "            score = [i for i in range(60)]\n",
    "            scoreList = []\n",
    "\n",
    "            for index in range(len(testData)):\n",
    "                scoreList.append(rateFeatureList(individuum, trainData[index1], testData[index], weightParaCount))\n",
    "\n",
    "            (sortScore, sortScoreList) = sortByArray(score, scoreList)\n",
    "\n",
    "            for index2 in range(len(sortScore)):\n",
    "                if sortScore[index2] == index1:\n",
    "                    scoreSort.append(index2)\n",
    "\n",
    "\n",
    "        scoreSort.sort()\n",
    "        median = len(scoreSort)/2\n",
    "        a = []\n",
    "        for i in range(50):\n",
    "            a.append(scoreSort[i])\n",
    "        ret = np.mean(a)\n",
    "        return ret    \n",
    "    else:\n",
    "        print \"Wrong Flag\"\n",
    "    \n",
    "def sortByArray(X, Y):\n",
    "    sortX = [x for (y,x) in sorted(zip(Y,X))]\n",
    "    sortY = sorted(Y)\n",
    "    return (sortX, sortY)\n",
    "\n",
    "def createPopulation(numberOfIndividuum, weightParaCount, flag):\n",
    "    population = [0 for i in range(numberOfIndividuum)]\n",
    "    \n",
    "    for __index4 in range(numberOfIndividuum):\n",
    "        c = createRandomChromosom()\n",
    "        population[__index4] = Individuum(c)\n",
    "        \n",
    "    calculateScoreOverPopulation(population, weightParaCount, flag)\n",
    "    return population\n",
    "\n",
    "def breed(population, weightParaCount, mutationRate, flag, flagMutation):\n",
    "    children = [0 for i in range(int(len(population) / 2))]\n",
    "    childrenIndex = 0\n",
    "    for __index in range(0, len(population), 2):\n",
    "        children[childrenIndex] = makeChild(population[__index], population[__index + 1], weightParaCount, mutationRate, flag, flagMutation)\n",
    "        childrenIndex = childrenIndex + 1\n",
    "        \n",
    "    return children\n",
    "\n",
    "\n",
    "def combineChildrenAndParents(population, children):\n",
    "    \n",
    "    lenght_pop = len(population)\n",
    "    lenght_chi = len(children)\n",
    "    \n",
    "    lenght_combined = lenght_pop + lenght_chi\n",
    "    \n",
    "    everyInd = [0 for i in range(lenght_combined)]\n",
    "    \n",
    "    for i in range(lenght_pop):\n",
    "        everyInd[i] = population[i]\n",
    "    for i in range(lenght_chi):\n",
    "        everyInd[i + lenght_pop] = children[i]\n",
    "                   \n",
    "    everyInd = sortPopulation(everyInd)\n",
    "    \n",
    "    result = [0 for i in range(lenght_pop)]\n",
    "    \n",
    "    for i in range(lenght_pop):\n",
    "        result[i] = everyInd[i]\n",
    "            \n",
    "    return result\n",
    "\n",
    "\n",
    "# ------------------- SIDE EFFECTS ------------------- #\n",
    "def calculateScoreOverPopulation(population, weightParaCount, flag):\n",
    "    for i in range(len(population)):\n",
    "        population[i].score = createScore(population[i], trainData, testData, weightParaCount, flag)\n",
    "        \n",
    "def sortPopulation(population):\n",
    "    return sorted(population, key=lambda Individuum: Individuum.score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def genLoop(populationSize, iterationen, stagnation, weightParaCount, mutationRate, flagMutation, flag):\n",
    "    pop = createPopulation(populationSize, weightParaCount, flag)\n",
    "    topten = [0 for i in range(10)]\n",
    "    durchschnitt = 0\n",
    "    countIter = 0\n",
    "    \n",
    "    bestFit = []\n",
    "    \n",
    "    for y in range(iterationen):\n",
    "        c = breed(pop, weightParaCount, mutationRate, flag, flagMutation)\n",
    "        pop = combineChildrenAndParents(pop,c)\n",
    "        if y%10 == 0:\n",
    "            print \"iteration \", y, \" from \", iterationen, \" in total.\"\n",
    "            print \"10 best scores:\"\n",
    "            for i in range(10):\n",
    "                print \"\\t\", pop[i].score\n",
    "                \n",
    "        for i in range(10):\n",
    "                topten[i] = pop[i].score\n",
    "                \n",
    "        bestFit.append(topten[0])\n",
    "        \n",
    "        if (np.mean(topten)-durchschnitt == 0):\n",
    "            countIter = countIter + 1\n",
    "            if countIter >= stagnation:        \n",
    "                print \"Iterated \", y, \" times.\"\n",
    "                print \"-------------------------------------- stagnation!\"\n",
    "                print \"\\n\"\n",
    "                print \"Best Score: \", pop[0].score \n",
    "                print \"Parameter count: \", getReducedAttributeListSize(pop[0])\n",
    "                print \"FL: \\n\", pop[0].featureList\n",
    "                return (pop, bestFit)\n",
    "        else: \n",
    "            durchschnitt = np.mean(topten)\n",
    "            countIter = 0\n",
    "    \n",
    "    print \"\\n\"\n",
    "    print \"Iterated \", iterationen, \" times.\"\n",
    "    print \"\\n\"\n",
    "    print \"Best Score: \", pop[0].score \n",
    "    print \"Parameter count: \", getReducedAttributeListSize(pop[0])\n",
    "    print \"FL: \\n\", pop[0].featureList\n",
    "    \n",
    "    print bestFit1\n",
    "    \n",
    "    return (pop, bestFit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genetischer Algorithmus\n",
    "\n",
    "Paramater der Funktion genLoop(populationSize, iterationen, stagnation, weightParaCount, mutationRate, flag)\n",
    "\n",
    "+ **populationSize**: Gibt an aus wievielen Individuuen die Population besteht. In unserem Algoritmus ist diese statisch.\n",
    "\n",
    "\n",
    "+ **iterationen**: Die Maximale Anzahl der Iterationen.\n",
    "\n",
    "\n",
    "+ **stagnation**: Gibt die Zahl der Iterationen an, bevor der Algorithmus bei Stagnation abbricht. Es wird überprüft ob die 10 besten Individuuen sich noch verändern. Wenn das nicht der Fall ist, dann bricht die Loop ab.\n",
    "\n",
    "\n",
    "+ **weightParaCount**: Damit der Algorithmus nicht zu der Lösung kommt alle Features auf False zu setzen und dadurch die Distanz zu minimieren, wird beim berechnen der Fitness, der Wert mit der Anzahl der benutzten Parameter gewichtet.\n",
    "\n",
    "\n",
    "+ **mutationRate**: Gibt die Mutationswahrscheinlichkeit an.\n",
    "\n",
    "\n",
    "+ **flagMutation**: Gibt an welche Art der Mutation benutzt wird.\n",
    "    + 1 -> bei X% der Individuuen wird ein Feature des Chromosoms umgedreht.\n",
    "    + 2 -> bei X% der Features eines Chromosoms werden umgedreht ( 42 mal so viele Mutationen wie bei Flag=1)\n",
    "\n",
    "\n",
    "+ **flag**: Hier kann Methode zur Berechnung der Fitness eingestellt werden. \n",
    "    + 1 -> Als Fitness wird der Durchschnitt der Euklidische Distanz zwischen Teil 1 und 2 aller Songs pro Chromosom benutzt.\n",
    "    + 2 -> So wie es Hr. Maucher in der Aufgabenstellung vorgesehen hat\n",
    "    + 3 -> So wie in der Aufgabenstellung, aber anstatt den mittleren Rang zu nehmen, wird aus den ersten 50 Rängen der Durchschnitt gebildet. (um Ausreißern entgegen zu wirken)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration  0  from  50  in total.\n",
      "10 best scores:\n",
      "\t1\n",
      "\t1\n",
      "\t1\n",
      "\t1\n",
      "\t1\n",
      "\t1\n",
      "\t1\n",
      "\t1\n",
      "\t1\n",
      "\t1\n",
      "Iterated  5  times.\n",
      "-------------------------------------- stagnation!\n",
      "\n",
      "\n",
      "Best Score:  1\n",
      "Parameter count:  18\n",
      "FL: \n",
      "[True, False, False, False, False, False, False, False, True, True, True, False, False, False, True, True, True, True, False, True, False, True, False, False, True, True, True, False, True, False, False, False, True, False, False, True, False, True, False, False, False, True]\n"
     ]
    }
   ],
   "source": [
    "uresult, bFit = genLoop(\n",
    "    populationSize=100,\n",
    "    iterationen=50, \n",
    "    stagnation=5, \n",
    "    weightParaCount=8, \n",
    "    mutationRate=.1, \n",
    "    flagMutation=1, \n",
    "    flag=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(range(len(bFit)), bFit)\n",
    "plt.ylabel('best Individual')\n",
    "plt.xlabel('iteration')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es ist bemerkenswert das es so extrem schnell konvergiert. Da 1 der beste Score ist, kann darübe rhinaus nicht optimiert werden. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Music Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print uresult[0].featureList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering und automatische Playlistgenerierung\n",
    "Implementieren Sie ein hierarchisches Clustering aller Subsequenzen in _subFeaturesTrain1.csv_. Diese _.csv_-Datei enthält nur die im vorigen Schritt ermittelten wichtigsten Merkmale. Das hierarchische Clustering ist in einem Dendrogram der Art wie in der unten gegebenen Abbildung zu visualisieren.\n",
    "\n",
    "Die gefundenen Cluster sind mit den zugehörigen Musiktiteln in der Konsole auszugeben. \n",
    "\n",
    "**Aufgaben:**\n",
    "\n",
    "1. Optimieren Sie die Parameter\n",
    "\n",
    "    1. metric (Ähnlichkeitsmaß)\n",
    "    2. linkage method\n",
    "    3. Clusteranzahl\n",
    "    \n",
    "2. Für welche Parameterkonstellation erlangen Sie das für Sie subjektiv betrachtet günstigste Ergebnis?\n",
    "3. Überlegen Sie sich Ansätze um diese Art der Musikgruppierung zu verbessern?\n",
    "\n",
    "![Abbildung Music Clustering](https://www.hdm-stuttgart.de/~maucher/ipnotebooks/DataMining//Bilder/playlistCluster.png \"Music Clustering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "np.set_printoptions(precision=5, suppress=True) \n",
    "\n",
    "#takes optimized featureList as input, returns the Dataframe only with selected features \n",
    "def createSubFeaturesTrain1(featureList):\n",
    "    songDataframe = pd.read_csv('FeatureFileTrainingAllList1.csv')\n",
    "    dropColumnsList =[]\n",
    "    \n",
    "    for i in range(len(featureList)):\n",
    "        if featureList[i] == False:\n",
    "            dropColumnsList.append(i)\n",
    "            \n",
    "    songDataframe = songDataframe.drop(songDataframe.columns[dropColumnsList], axis = 1)\n",
    "    \n",
    "    return songDataframe\n",
    "\n",
    "#takes a dataframe sorted by features cuts the labels at index 1 as list \n",
    "#and saves the features as np array of feature arrays\n",
    "def createClusterMatrixAndLabelList(featureList):\n",
    "    \n",
    "    songDataframe = createSubFeaturesTrain1(featureList)\n",
    "    labelList = songDataframe[songDataframe.columns[0]].tolist()\n",
    "    songDataframeFeatures = songDataframe.drop(songDataframe.columns[0], axis =1)\n",
    "    \n",
    "    clusterMatrix = []\n",
    "\n",
    "    for i in range(len(songDataframeFeatures.index)):\n",
    "        clusterMatrix.append(songDataframeFeatures.iloc[i].tolist())\n",
    "        \n",
    "    return (clusterMatrix, labelList)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#SubFeaturesTrain1 = createSubFeaturesTrain1(uresult[0].featureList)\n",
    "\n",
    "(clusterMatrix, labelList)= createClusterMatrixAndLabelList(uresult[0].featureList)\n",
    "\n",
    "clusterMatrixNP = np.asarray(clusterMatrix)\n",
    "X = clusterMatrixNP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B optimierung der linkage methode\n",
    "\n",
    "'ward' als linkage Methode zeigt die nachvollziehbarsten Ergebnisse im Dendogram z.b. Adele Songs werden zu Adele Songs geclustert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# generate the linkage matrix\n",
    "Z = linkage(X, 'ward') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Überprüfung des  'Cophenetic Correlation Coefficient'\n",
    "\n",
    "Der Cophenetic Correlation Coefficient überprüft die paarweise Distanz zwischen den samples die durch das clustering impliziert wird. Es zeigt wie sehr das clustering die Originaldistanz abbildet. Der Wert liegt zwischen 0 == sehr schlechte Abbildung und 1 == sehr gute Abbildung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import cophenet\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "c, coph_dists = cophenet(Z, pdist(X))\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Dendogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calculate full dendrogram\n",
    "plt.figure(figsize=(25, 10))\n",
    "plt.title('Hierarchical Clustering Dendrogram')\n",
    "plt.xlabel('sample index')\n",
    "plt.ylabel('distance')\n",
    "dendrogram(\n",
    "    Z,\n",
    "    leaf_font_size=8.,  # font size for the x axis labels\n",
    "    labels=labelList,\n",
    "    orientation = 'right'\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Ansätze zur Verbesserung\n",
    "\n",
    "Überlegen Sie sich Ansätze um diese Art der Musikgruppierung zu verbessern?\n",
    "spezfische Ansätze:\n",
    "\n",
    "Alternativen zum Hierarchical Clustering verwenden, je nach Dimension der bereitgestellten Daten\n",
    "\n",
    "- Hierarchical Clustering\n",
    "    - Vorteil: Hohe Genauigkeit\n",
    "    - Probleme: Langsam\n",
    "- k-Mean-Algorithmus: geringe Genauigkeit da er nicht die beste Lösung finden muss, hohe Geschwindigkeit\n",
    "    - wenn man eine hohe Genauigkeit haben will —> mehrmals ausühren —> wieder langsamer\n",
    "    - weiterer Nachteil: Probleme bei gestreuten Werten\n",
    "- Density Based Clustering - ähnliche Vorteile wie HC aber schlechter bei hochdimensionalen Daten\n",
    "\n",
    "### Struktur des Liedes\n",
    "\n",
    "Es werden jeweils Hälften der Songs genommen und die erste Hälfte eines Songs mit der Liste der zweiten Hälfte aller Songs verglichen. Dies lässt aber Unterschiede zwischen der ersten und der zweiten Hälfte eines Lieds außer Acht. Viele Songs haben etwa Intros, welche meist deutlich ruihger sind als der Rest des Songs. Da Intros aber oft recht lang sind, verfälschen sie hier das Ergebnis. Man müsste also einen Algorithmus implementieren, der auf die Unterschiede innerhalb eines einzelnen Liedes eingeht.\n",
    "\n",
    "### generelle Ansätze\n",
    "\n",
    "- größere Menge an Daten\n",
    "- Feedback durch User (User wirft einzelne Songs wieder aus Playlist oder fügt neue hinzu)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
