{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import random\n",
    "\n",
    "DATA_PATH = 'D:\\\\Data Mining\\\\data\\\\'\n",
    "\n",
    "testdata = pd.read_csv(DATA_PATH + \"bigmerge.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testdata = testdata.drop('gender', axis=1)\n",
    "testdata = testdata.drop('age', axis=1)\n",
    "testdata = testdata.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#testdata needs to be without gender and age-group\n",
    "dataframe = testdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set(['M39+', 'F27-28', 'M32-38', 'M23-26', 'F43+', 'M22-', 'F33-42', 'F23-', 'F24-26', 'F29-32', 'M27-28', 'M29-31'])\n"
     ]
    }
   ],
   "source": [
    "#23290 IDs\n",
    "#1466 lenght of one Dataset\n",
    "#23290 * 1466 = 3506672\n",
    "\n",
    "#traindata length encodearray 22766980\n",
    "\n",
    "#Tainset = 15530\n",
    "#Testset = 7760\n",
    "\n",
    "#Groups in Labellists\n",
    "################\n",
    "#0 = M22-\n",
    "#1 = M23-26\n",
    "#2 = M27-28\n",
    "#3 = M29-31\n",
    "#4 = M32-38\n",
    "#5 = M39+\n",
    "#6 = F23-\n",
    "#7 = F24-26\n",
    "#8 = F27-28\n",
    "#9 = F29-32\n",
    "#10 = F33-42\n",
    "#11 = F43+\n",
    "\n",
    "print set(dataframe['group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#returns a list of Label Names label 0 = 'M22-' 1 = ''\n",
    "def getLabelNames():\n",
    "    labelNames = ['M22-','M23-26','M27-28','M29-31','M32-38','M39+','F23-','F24-26','F27-28','F29-32','F33-42','F43+']\n",
    "    \n",
    "    return labelNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getTrainDataframe(dataframe):\n",
    "    idList = dataframe[dataframe.columns[0]].unique()\n",
    "    trainset = pd.DataFrame(index=range(0), columns=['device_id','group','phone_brand','device_model','category'])\n",
    "    \n",
    "    for i in range(15530):\n",
    "        tmpdf = dataframe.loc[dataframe[dataframe.columns[0]] == idList[i]]\n",
    "        frames = [tmpdf, trainset]\n",
    "        trainset = pd.concat(frames)\n",
    "    \n",
    "    return trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTestDataframe(dataframe):\n",
    "    idList = dataframe[dataframe.columns[0]].unique()\n",
    "    testset = pd.DataFrame(index=range(0), columns=['device_id','group','phone_brand','device_model','category'])\n",
    "    \n",
    "    for i in range(15530,23289):\n",
    "        tmpdf = dataframe.loc[dataframe[dataframe.columns[0]] == idList[i]]\n",
    "        frames = [tmpdf, testset]\n",
    "        testset = pd.concat(frames)\n",
    "    \n",
    "    return testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getLabelList(dataframe):\n",
    "    #get all IDs, make a list\n",
    "    idList = dataframe[dataframe.columns[0]].unique()\n",
    "    #enumerate idList and create a list with age group\n",
    "    labelList = []\n",
    "    for i in range(len(idList)):\n",
    "        value = dataframe.loc[dataframe['device_id'] == idList[i], 'group'].values[0]\n",
    "        labelList.append(value)\n",
    "        \n",
    "    #replace all values in labelList with GroupValues int between 0-11   \n",
    "    for v in range(len(labelList)):\n",
    "        if labelList[v] == 'M22-':\n",
    "            labelList[v]=0\n",
    "        elif labelList[v] == 'M23-26':\n",
    "            labelList[v]=1\n",
    "        elif labelList[v] == 'M27-28':\n",
    "            labelList[v]=2    \n",
    "        elif labelList[v] == 'M29-31':\n",
    "            labelList[v]=3   \n",
    "        elif labelList[v] == 'M32-38':\n",
    "            labelList[v]=4\n",
    "        elif labelList[v] == 'M39+':\n",
    "            labelList[v]=5\n",
    "        elif labelList[v] == 'F23-':\n",
    "            labelList[v]=6\n",
    "        elif labelList[v] == 'F24-26':\n",
    "            labelList[v]=7\n",
    "        elif labelList[v] == 'F27-28':\n",
    "            labelList[v]=8\n",
    "        elif labelList[v] == 'F29-32':\n",
    "            labelList[v]=9\n",
    "        elif labelList[v] == 'F33-42':\n",
    "            labelList[v]=10\n",
    "        elif labelList[v] == 'F43+':\n",
    "            labelList[v]=11\n",
    "        \n",
    "    return labelList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create traindataframe\n",
    "traindataframe = getTrainDataframe(dataframe)\n",
    "\n",
    "#create trainlabellist\n",
    "trainlabellist = getLabelList(traindataframe)\n",
    "\n",
    "#create testdataframe\n",
    "testdataframe = getTestDataframe(dataframe)\n",
    "\n",
    "#create testlabellist\n",
    "testlabellist = getLabelList(testdataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#takes dataframe and returns a random dataset by id\n",
    "def getRandomDataset(dataframe):\n",
    "    #get all IDs, make a list\n",
    "    idList = dataframe[dataframe.columns[0]].unique()\n",
    "    #get a random id from list\n",
    "    randomID = idList[random.randint(0,len(idList)-1)]\n",
    "    #get the random dataset by id\n",
    "    randomDataSet = dataframe.loc[dataframe[dataframe.columns[0]] == randomID]\n",
    "   \n",
    "    return randomDataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataframe = testdata\n",
    "\n",
    "#takes dataframe and returns python dictionary with unique values and headers\n",
    "def createMatrixSizeDic(dataframe):\n",
    "    #slice our id away\n",
    "    dataframe = dataframe.drop(dataframe.columns[0], axis=1)\n",
    "    dataframe = dataframe.drop('group', axis=1)\n",
    "    #get headers to list\n",
    "    headers = list(dataframe.columns.values)\n",
    "    #count values distinct\n",
    "    sizeDic = {headers[x]:dataframe[headers[x]].unique() for x in range(len(headers))}\n",
    "    \n",
    "    return sizeDic\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#creates a one hot encode array\n",
    "def createMainDataOneHotEncode(dataframeall, dataframe):\n",
    "    oneHotEncodeArray = []\n",
    "    \n",
    "    #get all IDs, make a list\n",
    "    idList = dataframe[dataframe.columns[0]].unique()\n",
    "    #get the dataframe size Dictionary\n",
    "    sizeDic = createMatrixSizeDic(dataframeall)\n",
    "\n",
    "    for ind in range(len(idList)):\n",
    "        \n",
    "        #get the random dataset by id\n",
    "        DataSet = dataframe.loc[dataframe[dataframe.columns[0]] == idList[ind]]\n",
    "        \n",
    "        #get random Group\n",
    "        #DataSetGroup = DataSet['group'].unique()\n",
    "        #DataSetGroupStr = randomDataSetGroup[0]\n",
    "    \n",
    "#    print randomDataSetGroupStr\n",
    "\n",
    "        #print DataSet\n",
    "\n",
    "\n",
    "        #drop the id row of the random Dataset\n",
    "        DataSet = DataSet.drop(DataSet.columns[0], axis=1)\n",
    "    \n",
    "        #drop group Row\n",
    "        DataSet = DataSet.drop('group', axis=1)\n",
    "    \n",
    "        #get headers of randomDataSet\n",
    "        headers = list(DataSet.columns.values)\n",
    "    \n",
    "        #create utilityLists oneHotEncodeDataset with sizeDic Parameters and randomDataset\n",
    "        tmpList = []\n",
    "        for key, value in sizeDic.iteritems():\n",
    "            for x in value:\n",
    "                tmpList.append(x)\n",
    "            \n",
    "#   print tmpList\n",
    "    \n",
    "        tmpList2 = []\n",
    "        for column, row in DataSet.iterrows():\n",
    "            for i in range(len(headers)):\n",
    "                tmpList2.append(row[headers[i]])\n",
    "            \n",
    "        #remove duplicates\n",
    "        tmpList2 = set(tmpList2)\n",
    "        \n",
    "#   print tmpList2\n",
    "    \n",
    "        #replace in tmpList all values with 1 when found in tmpList2 the rest values with 0\n",
    "        for index, item in enumerate(tmpList2):\n",
    "            for ind, val in enumerate(tmpList):\n",
    "                if (item == val):\n",
    "                    tmpList[ind] = 1\n",
    "    \n",
    "        for index, item in enumerate(tmpList):\n",
    "            if (item != 1):\n",
    "                tmpList[index] = 0\n",
    "            \n",
    "        oneHotEncodeArray.extend(tmpList)\n",
    "#   print len(oneHotEncodeArray[randomDataSetGroupStr:tmpList])\n",
    "    \n",
    "    return oneHotEncodeArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#create Traindata and Testdata as numpy array\n",
    "\n",
    "x = createMainDataOneHotEncode(dataframe, traindataframe)\n",
    "\n",
    "TrainData = np.array(x)\n",
    "\n",
    "print len(x)\n",
    "\n",
    "y = createMainDataOneHotEncode(dataframe, testdataframe)\n",
    "\n",
    "TestData = np.array(y)\n",
    "\n",
    "print len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TrainData' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-282549430d57>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#save the trainfile and testfile as .npy array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDATA_PATH\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'trainData.npy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTrainData\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_pickle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfix_imports\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDATA_PATH\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/trainLabels.npy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainlabellist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_pickle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfix_imports\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'TrainData' is not defined"
     ]
    }
   ],
   "source": [
    "#save the trainfile and testfile as .npy array  \n",
    "    \n",
    "np.save(DATA_PATH + 'trainData.npy', TrainData, allow_pickle=True, fix_imports=True)\n",
    "np.save(DATA_PATH + '/trainLabels.npy', trainlabellist, allow_pickle=True, fix_imports=True)\n",
    "\n",
    "np.save(DATA_PATH + 'testData.npy', TrainData, allow_pickle=True, fix_imports=True)\n",
    "np.save(DATA_PATH + 'testLabels.npy', testlabellist, allow_pickle=True, fix_imports=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save the labelnames\n",
    "labelNames = getLabelNames()\n",
    "\n",
    "np.save('/home/daniel/labelNames.npy', labelNames, allow_pickle=True, fix_imports=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#creates a one hot encode array\n",
    "def createRandomOneHotEncode(dataframe):\n",
    "    #get the dataframe size Dictionary\n",
    "    sizeDic = createMatrixSizeDic(dataframe)\n",
    "    #get a random Dataset\n",
    "    randomDataSet = getRandomDataset(dataframe)\n",
    "    #get random Group\n",
    "    randomDataSetGroup = randomDataSet['group'].unique()\n",
    "    randomDataSetGroupStr = randomDataSetGroup[0]\n",
    "    \n",
    "#    print randomDataSetGroupStr\n",
    "    #drop the id row of the random Dataset\n",
    "    randomDataSet = randomDataSet.drop(randomDataSet.columns[0], axis=1)\n",
    "    #drop group Row\n",
    "    randomDataSet = randomDataSet.drop('group', axis=1)\n",
    "    #get headers of randomDataSet\n",
    "    headers = list(randomDataSet.columns.values)\n",
    "    #create utilityLists oneHotEncodeDataset with sizeDic Parameters and randomDataset\n",
    "    tmpList = []\n",
    "    for key, value in sizeDic.iteritems():\n",
    "        for x in value:\n",
    "            tmpList.append(x)\n",
    "            \n",
    "#   print tmpList22\n",
    "    \n",
    "    tmpList2 = []\n",
    "    for column, row in randomDataSet.iterrows():\n",
    "        for i in range(len(headers)):\n",
    "            tmpList2.append(row[headers[i]])\n",
    "            \n",
    "    #remove duplicates\n",
    "    tmpList2 = set(tmpList2)\n",
    "#   print tmpList2\n",
    "    \n",
    "    #replace in tmpList all values with 1 when found in tmpList2 the rest values with 0\n",
    "    for index, item in enumerate(tmpList2):\n",
    "        for ind, val in enumerate(tmpList):\n",
    "            if (item == val):\n",
    "                tmpList[ind] = 1\n",
    "    \n",
    "    for index, item in enumerate(tmpList):\n",
    "        if (item != 1):\n",
    "            tmpList[index] = 0\n",
    "            \n",
    "    oneHotEncodeArray = {randomDataSetGroupStr:tmpList}\n",
    "#   print len(oneHotEncodeArray[randomDataSetGroupStr:tmpList])\n",
    "    \n",
    "    return oneHotEncodeArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testdataframe = getTestDataframe(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print getLabelList(dataframe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(getIDList(dataframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "getRandomDataset(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "OneHot = createOneHotEncode(dataframe)\n",
    "\n",
    "print len(OneHot.values()[0])\n",
    "\n",
    "#1466\n",
    "\n",
    "print OneHot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
